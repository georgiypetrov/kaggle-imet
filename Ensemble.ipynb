{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "from typing import Dict\n",
    "from imet.utils import binarize_prediction, seed_everything\n",
    "import warnings\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['densenet201', 'densenet121', 'resnet50', 'resnet101', 'se_resnet50', 'resnet34', 'nasnetamobile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data: np.array, ids: np.array):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._ids = ids\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._ids.shape[0]\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        return torch.tensor(self._data[idx]), self._ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_fold(models, test=True, fold=0):\n",
    "    filename = 'test' if test else 'val'\n",
    "    preds = np.array([pd.read_hdf(f'zoo/model_{model}_fold_{fold}/{filename}.h5').values for model in models])\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_ids():\n",
    "    return pd.read_hdf(f'zoo/model_resnet50_fold_0/test.h5').index.values\n",
    "\n",
    "\n",
    "def get_preds(models, test=True):\n",
    "    preds_by_fold = []\n",
    "    for fold in range(5):\n",
    "        preds = get_preds_fold(models, test=test, fold=fold)\n",
    "        preds_by_fold.append(preds)\n",
    "    return np.array(preds_by_fold)\n",
    "\n",
    "\n",
    "def ids_to_labels(attribute_ids):\n",
    "    labels = np.zeros(1103)\n",
    "    indexes = list(map(int, attribute_ids.split()))\n",
    "    labels[indexes] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "def validation(model: nn.Module, criterion, valid_loader, use_cuda) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    all_losses, all_predictions, all_targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            all_targets.append(targets.numpy().copy())\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            all_losses.append(loss.item())\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    def get_score(y_pred):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=UndefinedMetricWarning)\n",
    "            return fbeta_score(\n",
    "                all_targets, y_pred, beta=2, average='samples')\n",
    "\n",
    "    metrics = {}\n",
    "    argsorted = all_predictions.argsort(axis=1)\n",
    "    for threshold in [0.05, 0.10, 0.15]:\n",
    "        metrics[f'valid_f2_th_{threshold:.2f}'] = get_score(\n",
    "            binarize_prediction(all_predictions, threshold, argsorted))\n",
    "    metrics['valid_loss'] = np.mean(all_losses)\n",
    "    print(' | '.join(f'{k} {v:.3f}' for k, v in sorted(\n",
    "        metrics.items(), key=lambda kv: -kv[1])))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_train_loader(models, test=True, fold=0):\n",
    "    preds = get_preds_fold(models, test, fold)\n",
    "    preds = preds.reshape((7443, 7, 1103, 1))\n",
    "    X = np.swapaxes(np.swapaxes(preds, 1, 3), 2, 3)\n",
    "    ids = get_ids()\n",
    "    print(ids.shape)\n",
    "    print(X.shape)\n",
    "    train_dataset = TestDataset(X, ids)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1000)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fold_0 = get_preds_fold(models, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7443,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(f'zoo/model_resnet50_fold_0/test.h5').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fold_0 = np.swapaxes(preds_fold_0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21816, 7, 1103)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_fold_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv('folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y_fold_0 = folds[folds['fold'] == 0]['attribute_ids'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y_fold_0 = np.array(list(map(ids_to_labels, preds_y_fold_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df1, df2):\n",
    "    n = len(df1)\n",
    "    v1, v2 = df1.values, df2.values\n",
    "    sums = np.multiply.outer(v2.sum(0), v1.sum(0))\n",
    "    stds = np.multiply.outer(v2.std(0), v1.std(0))\n",
    "    return pd.DataFrame((v2.T.dot(v1) - sums / n) / stds / n,\n",
    "                        df2.columns, df1.columns).abs().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_df(predictions):\n",
    "    concat = pd.concat((predictions))\n",
    "    return concat.groupby(concat.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleCNN(torch.nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EnsembleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 8, kernel_size=(3, 1)), nn.Dropout2d())\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(8, 16, kernel_size=(3, 1)), nn.Dropout2d())                \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(16, 32, kernel_size=(3, 1)), nn.Dropout2d())\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(32 * 1 * 1103, 1024), nn.Dropout2d())\n",
    "        self.fc2 = nn.Linear(1024, 1103)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "         \n",
    "        x = x.view(-1, 32 * 1 * 1103)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fold_0 = preds_fold_0.reshape((21816, 7, 1103, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.swapaxes(np.swapaxes(preds_fold_0, 1, 3), 2, 3)\n",
    "y = preds_y_fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 43\n",
      "valid_f2_th_0.05 0.195 | valid_f2_th_0.10 0.195 | valid_f2_th_0.15 0.195 | valid_f2_th_0.20 0.170 | valid_loss 0.037\n",
      "train_loss 24\n",
      "valid_f2_th_0.10 0.571 | valid_f2_th_0.15 0.564 | valid_f2_th_0.20 0.553 | valid_f2_th_0.05 0.541 | valid_loss 0.009\n",
      "train_loss 17\n",
      "valid_f2_th_0.10 0.588 | valid_f2_th_0.15 0.584 | valid_f2_th_0.20 0.571 | valid_f2_th_0.05 0.563 | valid_loss 0.008\n",
      "train_loss 15\n",
      "valid_f2_th_0.15 0.593 | valid_f2_th_0.10 0.592 | valid_f2_th_0.20 0.586 | valid_f2_th_0.05 0.564 | valid_loss 0.008\n",
      "epoch = 3 lr = 0.0003\n",
      "train_loss 13\n",
      "valid_f2_th_0.15 0.602 | valid_f2_th_0.10 0.602 | valid_f2_th_0.20 0.591 | valid_f2_th_0.05 0.584 | valid_loss 0.008\n",
      "train_loss 13\n",
      "valid_f2_th_0.15 0.603 | valid_f2_th_0.10 0.602 | valid_f2_th_0.20 0.593 | valid_f2_th_0.05 0.582 | valid_loss 0.008\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.602 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.593 | valid_f2_th_0.05 0.582 | valid_loss 0.008\n",
      "epoch = 6 lr = 6e-05\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.602 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.593 | valid_f2_th_0.05 0.582 | valid_loss 0.008\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.602 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.593 | valid_f2_th_0.05 0.583 | valid_loss 0.008\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.603 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.593 | valid_f2_th_0.05 0.583 | valid_loss 0.008\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.602 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.592 | valid_f2_th_0.05 0.583 | valid_loss 0.008\n",
      "train_loss 12\n",
      "valid_f2_th_0.10 0.603 | valid_f2_th_0.15 0.602 | valid_f2_th_0.20 0.592 | valid_f2_th_0.05 0.583 | valid_loss 0.008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d1146397eae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = EnsembleCNN().cuda()\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    lr = 3e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataset = utils.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train.astype(np.float32))) # create your datset\n",
    "    valid_dataset = utils.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test.astype(np.float32))) # create your datset\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8)\n",
    "    best_valid_loss = 10000\n",
    "    zloy = 0\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print('train_loss %d' % running_loss)\n",
    "        running_loss = 0.0\n",
    "        valid_metrics = validation(model, criterion, valid_loader, True)\n",
    "        if epoch == 3:\n",
    "            print(f'epoch = {epoch} lr = {lr}')\n",
    "            lr = 6e-5\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        if epoch == 6:\n",
    "            print(f'epoch = {epoch} lr = {lr}')\n",
    "            lr = 1e-6\n",
    "            optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=lr)\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 61\n",
      "train_loss 43\n",
      "train_loss 39\n",
      "train_loss 34\n",
      "train_loss 30\n",
      "epoch = 4 lr = 0.0001\n",
      "train_loss 29\n",
      "train_loss 29\n",
      "epoch = 6 lr = 2e-05\n",
      "train_loss 28\n",
      "train_loss 28\n",
      "train_loss 28\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = EnsembleCNN().cuda()\n",
    "model.train()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "train_dataset = utils.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train.astype(np.float32))) # create your datset\n",
    "valid_dataset = utils.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test.astype(np.float32))) # create your datset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8)\n",
    "best_valid_loss = 10000\n",
    "zloy = 0\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('train_loss %d' % running_loss)\n",
    "    running_loss = 0.0\n",
    "#     valid_metrics = validation(model, criterion, valid_loader, True)\n",
    "    if epoch == 4:\n",
    "        print(f'epoch = {epoch} lr = {lr}')\n",
    "        lr = 2e-5\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    if epoch == 6:\n",
    "        print(f'epoch = {epoch} lr = {lr}')\n",
    "        lr = 4e-6\n",
    "        optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=lr)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 41\n",
      "train_loss 27\n",
      "train_loss 25\n",
      "train_loss 23\n",
      "train_loss 22\n",
      "train_loss 22\n",
      "train_loss 21\n",
      "epoch = 6 lr = 0.0003\n",
      "train_loss 21\n",
      "train_loss 20\n",
      "epoch = 8 lr = 6e-05\n",
      "train_loss 20\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model2 = EnsembleCNN().cuda()\n",
    "model2.train()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 3e-4\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=lr)\n",
    "train_dataset = utils.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train.astype(np.float32))) # create your datset\n",
    "valid_dataset = utils.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test.astype(np.float32))) # create your datset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=8)\n",
    "best_valid_loss = 10000\n",
    "zloy = 0\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('train_loss %d' % running_loss)\n",
    "    running_loss = 0.0\n",
    "#     valid_metrics = validation(model, criterion, valid_loader, True)\n",
    "    if epoch == 6:\n",
    "        print(f'epoch = {epoch} lr = {lr}')\n",
    "        lr = 6e-5\n",
    "        optimizer = torch.optim.Adam(model2.parameters(), lr = lr)\n",
    "    if epoch == 8:\n",
    "        print(f'epoch = {epoch} lr = {lr}')\n",
    "        lr = 1e-6\n",
    "        optimizer = torch.optim.SGD(model2.parameters(), momentum=0.9, lr=lr)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7443,)\n",
      "(7443, 1, 7, 1103)\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_train_loader(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predict:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Predict:  25%|██▌       | 2/8 [00:00<00:00, 15.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Predict:  50%|█████     | 4/8 [00:00<00:00, 15.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Predict:  75%|███████▌  | 6/8 [00:00<00:00, 16.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Predict: 100%|██████████| 8/8 [00:00<00:00, 17.95it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to pred2.h5\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "model.eval()\n",
    "all_outputs, all_ids = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, ids in tqdm.tqdm(test_loader, desc='Predict'):\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        all_outputs.append(outputs.data.cpu().numpy())\n",
    "        all_ids.extend(ids)\n",
    "df = pd.DataFrame(\n",
    "    data=np.concatenate(all_outputs),\n",
    "    index=all_ids,\n",
    "    columns=map(str, range(1103)))\n",
    "df.to_hdf('pred2.h5', 'prob', index_label='id')\n",
    "print(f'Saved predictions to pred2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1093</th>\n",
       "      <th>1094</th>\n",
       "      <th>1095</th>\n",
       "      <th>1096</th>\n",
       "      <th>1097</th>\n",
       "      <th>1098</th>\n",
       "      <th>1099</th>\n",
       "      <th>1100</th>\n",
       "      <th>1101</th>\n",
       "      <th>1102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10023b2cc4ed5f68</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045992</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.002723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100fbe75ed8fd887</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032825</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.063053</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101b627524a04f19</th>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.026945</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10234480c41284c6</th>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.005635</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.053629</td>\n",
       "      <td>0.023539</td>\n",
       "      <td>0.059371</td>\n",
       "      <td>0.121380</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.010871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023b0e2636dcea8</th>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048271</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>0.023854</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.020378</td>\n",
       "      <td>0.125742</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.004019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4         5  \\\n",
       "10023b2cc4ed5f68  0.000041  0.004746  0.000632  0.000200  0.000183  0.000494   \n",
       "100fbe75ed8fd887  0.000256  0.002444  0.000298  0.000062  0.000027  0.000063   \n",
       "101b627524a04f19  0.000204  0.001851  0.000627  0.000149  0.000528  0.000210   \n",
       "10234480c41284c6  0.001292  0.008975  0.002044  0.000695  0.002130  0.001384   \n",
       "1023b0e2636dcea8  0.001379  0.001385  0.000636  0.000461  0.004306  0.002927   \n",
       "\n",
       "                         6         7         8         9    ...         1093  \\\n",
       "10023b2cc4ed5f68  0.000402  0.000133  0.000493  0.001267    ...     0.045992   \n",
       "100fbe75ed8fd887  0.000045  0.000046  0.000130  0.000321    ...     0.032825   \n",
       "101b627524a04f19  0.000537  0.000079  0.001756  0.000135    ...     0.011145   \n",
       "10234480c41284c6  0.003359  0.000595  0.005635  0.000744    ...     0.036896   \n",
       "1023b0e2636dcea8  0.001647  0.000563  0.004016  0.000283    ...     0.048271   \n",
       "\n",
       "                      1094      1095      1096      1097      1098      1099  \\\n",
       "10023b2cc4ed5f68  0.000237  0.000895  0.002102  0.007947  0.023899  0.016448   \n",
       "100fbe75ed8fd887  0.000102  0.008818  0.007217  0.013293  0.015014  0.063053   \n",
       "101b627524a04f19  0.000246  0.001725  0.026945  0.005531  0.013237  0.060282   \n",
       "10234480c41284c6  0.001050  0.004956  0.053629  0.023539  0.059371  0.121380   \n",
       "1023b0e2636dcea8  0.000425  0.016674  0.023854  0.018106  0.020378  0.125742   \n",
       "\n",
       "                      1100      1101      1102  \n",
       "10023b2cc4ed5f68  0.001016  0.001723  0.002723  \n",
       "100fbe75ed8fd887  0.000750  0.003658  0.001463  \n",
       "101b627524a04f19  0.000582  0.006636  0.000940  \n",
       "10234480c41284c6  0.004508  0.035552  0.010871  \n",
       "1023b0e2636dcea8  0.000780  0.002628  0.004019  \n",
       "\n",
       "[5 rows x 1103 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = pd.read_csv('submission_nn_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023b2cc4ed5f68</td>\n",
       "      <td>13 79 147 322 725 776 813 830 1046 1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100fbe75ed8fd887</td>\n",
       "      <td>121 147 188 189 335 541 542 597 813 1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101b627524a04f19</td>\n",
       "      <td>147 161 188 335 612 671 813 864 1059 1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10234480c41284c6</td>\n",
       "      <td>147 189 194 671 776 780 830 1046 1059 1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023b0e2636dcea8</td>\n",
       "      <td>51 156 369 737 738 813 1019 1046 1059 1092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                               attribute_ids\n",
       "0  10023b2cc4ed5f68     13 79 147 322 725 776 813 830 1046 1092\n",
       "1  100fbe75ed8fd887    121 147 188 189 335 541 542 597 813 1092\n",
       "2  101b627524a04f19   147 161 188 335 612 671 813 864 1059 1092\n",
       "3  10234480c41284c6  147 189 194 671 776 780 830 1046 1059 1062\n",
       "4  1023b0e2636dcea8  51 156 369 737 738 813 1019 1046 1059 1092"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attribute_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000483014d91860</td>\n",
       "      <td>147 616 813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000fe2e667721fe</td>\n",
       "      <td>51 616 734 813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001614cb89646ee</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10041eb49b297c08</td>\n",
       "      <td>51 671 698 813 1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100501c227f8beea</td>\n",
       "      <td>13 404 492 903 1093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        attribute_ids\n",
       "0  1000483014d91860          147 616 813\n",
       "1  1000fe2e667721fe       51 616 734 813\n",
       "2  1001614cb89646ee                  776\n",
       "3  10041eb49b297c08  51 671 698 813 1092\n",
       "4  100501c227f8beea  13 404 492 903 1093"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df.apply (lambda row: len(row['attribute_ids'].split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['count'] == 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['attribute_ids'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1a38aeda6e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attribute_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/images/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['attribute_ids'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(['attribute_ids'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
